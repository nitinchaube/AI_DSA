{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Linear Regression\n",
    "y = mx + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100,1)\n",
    "true_w, true_b = 3,2\n",
    "y = true_w*X + true_b + 0.1*np.random.rand(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92397412],\n",
       "       [0.82001606],\n",
       "       [0.49848123],\n",
       "       [0.63802513],\n",
       "       [0.24557519],\n",
       "       [0.18999368],\n",
       "       [0.93516587],\n",
       "       [0.43583998],\n",
       "       [0.06556804],\n",
       "       [0.73834406],\n",
       "       [0.45559152],\n",
       "       [0.81696003],\n",
       "       [0.98527492],\n",
       "       [0.06430686],\n",
       "       [0.37134459],\n",
       "       [0.84367624],\n",
       "       [0.89007472],\n",
       "       [0.36874446],\n",
       "       [0.68047549],\n",
       "       [0.1877559 ],\n",
       "       [0.97760547],\n",
       "       [0.02848441],\n",
       "       [0.95991822],\n",
       "       [0.0841417 ],\n",
       "       [0.77640913],\n",
       "       [0.17686988],\n",
       "       [0.63772925],\n",
       "       [0.63411567],\n",
       "       [0.32355402],\n",
       "       [0.89389746],\n",
       "       [0.50205456],\n",
       "       [0.80907895],\n",
       "       [0.06883095],\n",
       "       [0.95761975],\n",
       "       [0.11934993],\n",
       "       [0.05143602],\n",
       "       [0.30705254],\n",
       "       [0.02466534],\n",
       "       [0.15953132],\n",
       "       [0.03050018],\n",
       "       [0.14536897],\n",
       "       [0.91207376],\n",
       "       [0.3695771 ],\n",
       "       [0.94231652],\n",
       "       [0.07098669],\n",
       "       [0.52840917],\n",
       "       [0.75552898],\n",
       "       [0.38919645],\n",
       "       [0.87949688],\n",
       "       [0.13102526],\n",
       "       [0.20835146],\n",
       "       [0.16828156],\n",
       "       [0.626152  ],\n",
       "       [0.67922418],\n",
       "       [0.87045974],\n",
       "       [0.82981131],\n",
       "       [0.12649523],\n",
       "       [0.72865141],\n",
       "       [0.50262179],\n",
       "       [0.36741577],\n",
       "       [0.80409206],\n",
       "       [0.68319549],\n",
       "       [0.80373338],\n",
       "       [0.28725096],\n",
       "       [0.19326661],\n",
       "       [0.94822324],\n",
       "       [0.19611806],\n",
       "       [0.53690914],\n",
       "       [0.33406812],\n",
       "       [0.67459793],\n",
       "       [0.30246119],\n",
       "       [0.22252782],\n",
       "       [0.1492528 ],\n",
       "       [0.30799903],\n",
       "       [0.27073615],\n",
       "       [0.39088325],\n",
       "       [0.6406232 ],\n",
       "       [0.62790066],\n",
       "       [0.75804379],\n",
       "       [0.48066449],\n",
       "       [0.58357702],\n",
       "       [0.90126006],\n",
       "       [0.70735545],\n",
       "       [0.71365452],\n",
       "       [0.09641285],\n",
       "       [0.14329957],\n",
       "       [0.08155832],\n",
       "       [0.19394696],\n",
       "       [0.77668879],\n",
       "       [0.02850867],\n",
       "       [0.97168029],\n",
       "       [0.66538066],\n",
       "       [0.44288683],\n",
       "       [0.75557572],\n",
       "       [0.14139582],\n",
       "       [0.28342355],\n",
       "       [0.90413015],\n",
       "       [0.1710836 ],\n",
       "       [0.910059  ],\n",
       "       [0.40967422]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing weights\n",
    "w , b =0, 0\n",
    "lr = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: w=0.405, b=0.706, loss=13.3031\n",
      "Epoch 100: w=2.667, b=2.224, loss=0.0109\n",
      "Epoch 200: w=2.916, b=2.092, loss=0.0012\n",
      "Epoch 300: w=2.970, b=2.062, loss=0.0008\n",
      "Epoch 400: w=2.982, b=2.056, loss=0.0008\n",
      "Epoch 500: w=2.985, b=2.055, loss=0.0008\n",
      "Epoch 600: w=2.986, b=2.054, loss=0.0008\n",
      "Epoch 700: w=2.986, b=2.054, loss=0.0008\n",
      "Epoch 800: w=2.986, b=2.054, loss=0.0008\n",
      "Epoch 900: w=2.986, b=2.054, loss=0.0008\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_hat = w*X + b\n",
    "    error = y_hat - y\n",
    "    dw = (2 / len(X)) * np.sum(error*X)\n",
    "    db = (2 / len(X))* np.sum(error)\n",
    "    w -= lr*dw\n",
    "    b -= lr*db\n",
    "    if epoch%100 == 0:\n",
    "        loss = np.mean(error**2)\n",
    "        print(f\"Epoch {epoch}: w={w:.3f}, b={b:.3f}, loss={loss:.4f}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Logistic Regression\n",
    "y = sigmoid (wX + b) <br>\n",
    "sigmoid(z) = 1 / (1+ e^-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1+ np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100,1)\n",
    "y = (X >0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter initialization\n",
    "w , b = 0, 0\n",
    "lr = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss=0.6532 | w 0.434 | b -0.149\n",
      "Epoch 100 | loss=0.2560 | w 5.708 | b -2.754\n",
      "Epoch 200 | loss=0.1871 | w 8.028 | b -3.898\n",
      "Epoch 300 | loss=0.1570 | w 9.573 | b -4.661\n",
      "Epoch 400 | loss=0.1394 | w 10.758 | b -5.246\n",
      "Epoch 500 | loss=0.1275 | w 11.733 | b -5.728\n",
      "Epoch 600 | loss=0.1188 | w 12.568 | b -6.141\n",
      "Epoch 700 | loss=0.1121 | w 13.302 | b -6.505\n",
      "Epoch 800 | loss=0.1066 | w 13.962 | b -6.831\n",
      "Epoch 900 | loss=0.1021 | w 14.562 | b -7.129\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    z = w*X + b\n",
    "    y_hat = sigmoid(z)\n",
    "    error = y_hat - y \n",
    "    loss = -np.mean(y*np.log(y_hat + 1e-8 ) + (1-y)* np.log(1-y_hat + 1e-8))\n",
    "    dz = y_hat - y \n",
    "    dw = np.mean(dz*X)\n",
    "    db = np.mean(dz)\n",
    "    w -= dw\n",
    "    b -= db\n",
    "    if epoch%100 == 0:\n",
    "        print(f\"Epoch {epoch} | loss={loss:.4f} | w {w:.3f} | b {b:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3:KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections  import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.x_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        distance = [np.linalg.norm(x-x_train) for x_train in self.x_train]\n",
    "        k_indices = np.argsort(distance)[:self.k]\n",
    "        k_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = Counter(k_labels).most_common(1)\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[[1 2]]]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[1,2],[2,3],[3,4],[6,7]])\n",
    "y_train = np.array([0,0,1,1])\n",
    "\n",
    "knn = KNN(k=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "X_test = np.array([[4,5]])\n",
    "print(\"Predicted:\", knn.predict(X_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: SVM (with kernel Trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
