{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gating Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, k=1):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self.gate(X)\n",
    "        print(f\"Gate Logits: {logits}\")\n",
    "        k_vals, k_indices = torch.topk(logits, self.k, dim = -1)\n",
    "        print(f\"Top k values are: {k_vals} and their indices are {k_indices}\")\n",
    "        scores = F.softmax(k_vals, dim = -1)\n",
    "        return k_indices, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experts(nn.Module):\n",
    "    def __init__(self, num_experts, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, input_dim)\n",
    "            ) for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "    def forward(self, X, indices):\n",
    "        batch_size, k = indices.shape\n",
    "        out = torch.zeros(batch_size, X.shape[1], device = X.device)\n",
    "        for i in range(k):\n",
    "            expert_idx = indices[:,i]\n",
    "            print(f\"Expert idx: {expert_idx}\")\n",
    "            for e in range(len(self.experts)):\n",
    "                mask = (expert_idx == e)\n",
    "                print(\"Mask: \",mask)\n",
    "                if mask.sum() > 0:\n",
    "                    x_selected = X[mask]\n",
    "                    print(f\" for expert {e} x selected is {x_selected}\")\n",
    "                    \n",
    "                    out[mask] += self.experts[e](x_selected)\n",
    "                    \n",
    "                    \n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOE_layer(nn.Module):\n",
    "    def __init__(self, input_dim,hidden_dim, num_experts=4, k=2):\n",
    "        super().__init__()\n",
    "        self.gate = Gate(input_dim, num_experts,k )\n",
    "        self.experts = Experts(num_experts, input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        topk_indices, topkscores = self.gate(x)\n",
    "        expert_output = self.experts(x, topk_indices)\n",
    "        return expert_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 12])\n",
      "X: tensor([[-0.3021,  0.7066, -1.4496, -1.4628, -0.4010,  0.1746,  1.2875, -0.3984,\n",
      "          1.9735, -1.3014,  0.6499,  1.1704],\n",
      "        [ 0.2978, -0.9248,  0.4805, -0.1547,  0.7873, -0.1263, -1.5822, -0.3890,\n",
      "         -1.5515,  0.4783,  0.7481,  1.4117],\n",
      "        [ 1.2824,  1.4317, -0.1390, -0.3534,  0.7705,  2.5527,  0.8637, -0.8920,\n",
      "          0.5932,  0.8116,  0.0730,  0.5651],\n",
      "        [ 0.9061,  1.9133,  0.5607, -2.0725,  0.1010, -0.3629, -0.0736,  1.9410,\n",
      "          0.8914,  0.9148,  0.8736,  0.5167]])\n",
      "Gate Logits: tensor([[ 0.3844,  0.6600,  0.9456, -0.5175],\n",
      "        [ 0.5285,  0.9110,  0.1191, -0.8722],\n",
      "        [ 0.4298, -0.2929,  0.8411,  0.4024],\n",
      "        [ 0.2496, -0.3347,  1.3059, -0.0569]], grad_fn=<AddmmBackward0>)\n",
      "Top k values are: tensor([[0.9456, 0.6600],\n",
      "        [0.9110, 0.5285],\n",
      "        [0.8411, 0.4298],\n",
      "        [1.3059, 0.2496]], grad_fn=<TopkBackward0>) and their indices are tensor([[2, 1],\n",
      "        [1, 0],\n",
      "        [2, 0],\n",
      "        [2, 0]])\n",
      "Expert idx: tensor([2, 1, 2, 2])\n",
      "Mask:  tensor([False, False, False, False])\n",
      "Mask:  tensor([False,  True, False, False])\n",
      " for expert 1 x selected is tensor([[ 0.2978, -0.9248,  0.4805, -0.1547,  0.7873, -0.1263, -1.5822, -0.3890,\n",
      "         -1.5515,  0.4783,  0.7481,  1.4117]])\n",
      "Mask:  tensor([ True, False,  True,  True])\n",
      " for expert 2 x selected is tensor([[-0.3021,  0.7066, -1.4496, -1.4628, -0.4010,  0.1746,  1.2875, -0.3984,\n",
      "          1.9735, -1.3014,  0.6499,  1.1704],\n",
      "        [ 1.2824,  1.4317, -0.1390, -0.3534,  0.7705,  2.5527,  0.8637, -0.8920,\n",
      "          0.5932,  0.8116,  0.0730,  0.5651],\n",
      "        [ 0.9061,  1.9133,  0.5607, -2.0725,  0.1010, -0.3629, -0.0736,  1.9410,\n",
      "          0.8914,  0.9148,  0.8736,  0.5167]])\n",
      "Mask:  tensor([False, False, False, False])\n",
      "Expert idx: tensor([1, 0, 0, 0])\n",
      "Mask:  tensor([False,  True,  True,  True])\n",
      " for expert 0 x selected is tensor([[ 0.2978, -0.9248,  0.4805, -0.1547,  0.7873, -0.1263, -1.5822, -0.3890,\n",
      "         -1.5515,  0.4783,  0.7481,  1.4117],\n",
      "        [ 1.2824,  1.4317, -0.1390, -0.3534,  0.7705,  2.5527,  0.8637, -0.8920,\n",
      "          0.5932,  0.8116,  0.0730,  0.5651],\n",
      "        [ 0.9061,  1.9133,  0.5607, -2.0725,  0.1010, -0.3629, -0.0736,  1.9410,\n",
      "          0.8914,  0.9148,  0.8736,  0.5167]])\n",
      "Mask:  tensor([ True, False, False, False])\n",
      " for expert 1 x selected is tensor([[-0.3021,  0.7066, -1.4496, -1.4628, -0.4010,  0.1746,  1.2875, -0.3984,\n",
      "          1.9735, -1.3014,  0.6499,  1.1704]])\n",
      "Mask:  tensor([False, False, False, False])\n",
      "Mask:  tensor([False, False, False, False])\n",
      "MoE Output: torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 12\n",
    "hidden_dim = 24\n",
    "batch_size = 4\n",
    "\n",
    "x = torch.randn(batch_size, input_dim)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"X: {x}\")\n",
    "moe = MOE_layer(input_dim, hidden_dim, num_experts=4, k=2)\n",
    "\n",
    "out = moe(x)\n",
    "print(\"MoE Output:\", out.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0273,  0.2877, -0.5854,  0.0574,  0.1356,  0.5124, -0.3650, -0.1347,\n",
       "         -0.1133,  0.2097, -0.3669,  0.3900],\n",
       "        [ 0.1926, -0.0400,  0.1400,  0.5526, -0.1984, -0.1806, -0.1975,  0.2709,\n",
       "         -0.1425, -0.1440,  0.6351,  0.0976],\n",
       "        [ 0.6171,  0.6376, -0.2093, -0.1238, -0.1605,  0.8789, -0.7390, -0.3176,\n",
       "         -0.1437,  0.5077,  0.3651,  0.4078],\n",
       "        [ 0.8661,  0.1895, -0.1989,  0.0059,  0.2289,  0.7442, -0.0927, -0.0368,\n",
       "          0.2981,  0.4837,  0.4913,  0.7385]], grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".agenticAIVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
